{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Youtube api to fetch comments from any video**\n",
    "- fetchs comments from given video, and store in a csv file\n",
    "- can be used for sentiment analysis, to see how people feel about a video\n",
    "\n",
    "**Alright please get your api key if you really want to use this script**\n",
    "- goto google cloud console (https://console.cloud.google.com/)\n",
    "- create a new project\n",
    "- enable the youtube data API v3\n",
    "- click on create aPI credentials option\n",
    "\n",
    "**Run In Google Colab**\n",
    "[Google Colab Link](https://colab.research.google.com/drive/1HwY3gVV7kEBZMtTGcMOR5d4GqG0LCEiE)\n",
    "\n",
    "**Let's Connect On Linkedin**\n",
    "[Linkedin](https://www.linkedin.com/in/hassan-zonee)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google-api-python-client\n",
      "  Downloading google_api_python_client-2.165.0-py2.py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting pandas\n",
      "  Using cached pandas-2.2.3-cp312-cp312-win_amd64.whl.metadata (19 kB)\n",
      "Collecting httplib2<1.0.0,>=0.19.0 (from google-api-python-client)\n",
      "  Downloading httplib2-0.22.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0 (from google-api-python-client)\n",
      "  Downloading google_auth-2.38.0-py2.py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting google-auth-httplib2<1.0.0,>=0.2.0 (from google-api-python-client)\n",
      "  Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5 (from google-api-python-client)\n",
      "  Downloading google_api_core-2.24.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting uritemplate<5,>=3.0.1 (from google-api-python-client)\n",
      "  Downloading uritemplate-4.1.1-py2.py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting numpy>=1.26.0 (from pandas)\n",
      "  Using cached numpy-2.2.4-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\dell\\desktop\\projects\\python--apis\\env\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting googleapis-common-protos<2.0.0,>=1.56.2 (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client)\n",
      "  Downloading googleapis_common_protos-1.69.2-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.19.5 (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client)\n",
      "  Downloading protobuf-6.30.1-cp310-abi3-win_amd64.whl.metadata (593 bytes)\n",
      "Collecting proto-plus<2.0.0,>=1.22.3 (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client)\n",
      "  Downloading proto_plus-1.26.1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in c:\\users\\dell\\desktop\\projects\\python--apis\\env\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (2.32.3)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client)\n",
      "  Downloading cachetools-5.5.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client)\n",
      "  Downloading pyasn1_modules-0.4.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client)\n",
      "  Downloading rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 (from httplib2<1.0.0,>=0.19.0->google-api-python-client)\n",
      "  Downloading pyparsing-3.2.3-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\dell\\desktop\\projects\\python--apis\\env\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Collecting pyasn1<0.7.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client)\n",
      "  Downloading pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dell\\desktop\\projects\\python--apis\\env\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dell\\desktop\\projects\\python--apis\\env\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dell\\desktop\\projects\\python--apis\\env\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dell\\desktop\\projects\\python--apis\\env\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (2025.1.31)\n",
      "Downloading google_api_python_client-2.165.0-py2.py3-none-any.whl (13.1 MB)\n",
      "   ---------------------------------------- 0.0/13.1 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/13.1 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.8/13.1 MB 2.2 MB/s eta 0:00:06\n",
      "   --- ------------------------------------ 1.3/13.1 MB 2.2 MB/s eta 0:00:06\n",
      "   ----- ---------------------------------- 1.8/13.1 MB 2.2 MB/s eta 0:00:06\n",
      "   ------- -------------------------------- 2.4/13.1 MB 2.3 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 2.6/13.1 MB 2.3 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 3.1/13.1 MB 2.3 MB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 3.7/13.1 MB 2.2 MB/s eta 0:00:05\n",
      "   ------------ --------------------------- 4.2/13.1 MB 2.2 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 4.7/13.1 MB 2.2 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 5.0/13.1 MB 2.2 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 5.5/13.1 MB 2.2 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 6.0/13.1 MB 2.2 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 6.6/13.1 MB 2.2 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 6.8/13.1 MB 2.2 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 7.3/13.1 MB 2.2 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 7.9/13.1 MB 2.2 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 8.4/13.1 MB 2.2 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 8.9/13.1 MB 2.2 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 9.4/13.1 MB 2.2 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 9.7/13.1 MB 2.2 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 10.2/13.1 MB 2.2 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 10.7/13.1 MB 2.2 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 11.3/13.1 MB 2.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 11.8/13.1 MB 2.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 12.1/13.1 MB 2.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 12.6/13.1 MB 2.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  13.1/13.1 MB 2.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 13.1/13.1 MB 2.2 MB/s eta 0:00:00\n",
      "Using cached pandas-2.2.3-cp312-cp312-win_amd64.whl (11.5 MB)\n",
      "Downloading google_api_core-2.24.2-py3-none-any.whl (160 kB)\n",
      "Downloading google_auth-2.38.0-py2.py3-none-any.whl (210 kB)\n",
      "Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl (9.3 kB)\n",
      "Downloading httplib2-0.22.0-py3-none-any.whl (96 kB)\n",
      "Downloading numpy-2.2.4-cp312-cp312-win_amd64.whl (12.6 MB)\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.6 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.8/12.6 MB 2.2 MB/s eta 0:00:06\n",
      "   ---- ----------------------------------- 1.3/12.6 MB 2.2 MB/s eta 0:00:06\n",
      "   ----- ---------------------------------- 1.8/12.6 MB 2.2 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 2.1/12.6 MB 2.3 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 2.6/12.6 MB 2.3 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 3.1/12.6 MB 2.3 MB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 3.7/12.6 MB 2.2 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 4.2/12.6 MB 2.2 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 4.5/12.6 MB 2.2 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 5.0/12.6 MB 2.2 MB/s eta 0:00:04\n",
      "   ----------------- ---------------------- 5.5/12.6 MB 2.2 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 5.8/12.6 MB 2.2 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 6.3/12.6 MB 2.2 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 6.8/12.6 MB 2.2 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 7.3/12.6 MB 2.2 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 7.9/12.6 MB 2.2 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 8.1/12.6 MB 2.2 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 8.7/12.6 MB 2.2 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 9.2/12.6 MB 2.2 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 9.7/12.6 MB 2.2 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 10.2/12.6 MB 2.2 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 10.5/12.6 MB 2.2 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 11.0/12.6 MB 2.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 11.5/12.6 MB 2.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 12.1/12.6 MB 2.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.6/12.6 MB 2.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.6/12.6 MB 2.2 MB/s eta 0:00:00\n",
      "Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Downloading uritemplate-4.1.1-py2.py3-none-any.whl (10 kB)\n",
      "Downloading cachetools-5.5.2-py3-none-any.whl (10 kB)\n",
      "Downloading googleapis_common_protos-1.69.2-py3-none-any.whl (293 kB)\n",
      "Downloading proto_plus-1.26.1-py3-none-any.whl (50 kB)\n",
      "Downloading protobuf-6.30.1-cp310-abi3-win_amd64.whl (431 kB)\n",
      "Downloading pyasn1_modules-0.4.1-py3-none-any.whl (181 kB)\n",
      "Downloading pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
      "Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Downloading pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "Installing collected packages: pytz, uritemplate, tzdata, pyparsing, pyasn1, protobuf, numpy, cachetools, rsa, pyasn1-modules, proto-plus, pandas, httplib2, googleapis-common-protos, google-auth, google-auth-httplib2, google-api-core, google-api-python-client\n",
      "Successfully installed cachetools-5.5.2 google-api-core-2.24.2 google-api-python-client-2.165.0 google-auth-2.38.0 google-auth-httplib2-0.2.0 googleapis-common-protos-1.69.2 httplib2-0.22.0 numpy-2.2.4 pandas-2.2.3 proto-plus-1.26.1 protobuf-6.30.1 pyasn1-0.6.1 pyasn1-modules-0.4.1 pyparsing-3.2.3 pytz-2025.2 rsa-4.9 tzdata-2025.2 uritemplate-4.1.1\n"
     ]
    }
   ],
   "source": [
    "!pip install google-api-python-client pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from googleapiclient.discovery import build\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fetch_youtube_comments(video_url, max_comments=500):\n",
    "    # please use your own api key. May your google cloud account gets blocked if you use mine, AAAAMEN!\n",
    "    api_key = \"AIzaSyBGlGsuz7OsshsxDKwrsYq8c0pJzHlHQDs\"\n",
    "    \n",
    "    # spliting the video id from url as youtube api only needs that\n",
    "    video_id = video_url.split(\"?v=\")[1]\n",
    "\n",
    "    # creating a youtube api client instance\n",
    "    youtube_api = build(\"youtube\", \"v3\", developerKey=api_key)\n",
    "\n",
    "    # initializing an empty list to store comments and a variable to track fetched comments\n",
    "    comments = []\n",
    "    authors = []\n",
    "    next_page_token = None\n",
    "    fetched_comments = 0\n",
    "    \n",
    "    # fetching comments from the video in batches of 100 each until max_comments is reached or no more comments are available\n",
    "    while fetched_comments < max_comments:\n",
    "        try:\n",
    "            response = youtube_api.commentThreads().list(\n",
    "                part=\"snippet\",\n",
    "                videoId=video_id,\n",
    "                maxResults=100,\n",
    "                pageToken=next_page_token\n",
    "            ).execute()\n",
    "            \n",
    "            for item in response[\"items\"]:\n",
    "                comment = item[\"snippet\"][\"topLevelComment\"][\"snippet\"][\"textDisplay\"]\n",
    "                author = item[\"snippet\"][\"topLevelComment\"][\"snippet\"][\"authorDisplayName\"]\n",
    "                comments.append(comment)\n",
    "                authors.append(author)\n",
    "                fetched_comments += 1\n",
    "                if fetched_comments >= max_comments:\n",
    "                    break\n",
    "            \n",
    "            next_page_token = response.get(\"nextPageToken\")\n",
    "            if not next_page_token:\n",
    "                break  \n",
    "            \n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            break\n",
    "\n",
    "    \n",
    "    # get video title to create filename from that\n",
    "    video_info = youtube_api.videos().list(part=\"snippet\", id=video_id).execute()\n",
    "    video_title = video_info[\"items\"][0][\"snippet\"][\"title\"]\n",
    "    \n",
    "    # get only first 5 words to include in filename, because title can be very very long\n",
    "    title_words = video_title.split()[:5]\n",
    "    filename = \"_\".join(title_words) + \"_comments.csv\"\n",
    "\n",
    "    # combine authors with their comments and make pandas dataframe\n",
    "    comments_and_authors = list(zip(authors, comments))\n",
    "    df = pd.DataFrame(comments_and_authors, columns=[\"author\",\"comment\"])\n",
    "    df.to_csv(filename, index=False)\n",
    "    print(f\"✅ Fetched {len(comments)} comments and saved to '{filename}'.\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fetched 500 comments and saved to 'if_David_Goggins_was_evil_comments.csv'.\n",
      "(500, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@Kbk07_</td>\n",
       "      <td>i want David to react to this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@TheDeepKing</td>\n",
       "      <td>This is diabolical 😂😂</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@Ivixation</td>\n",
       "      <td>i bet this actually triggered some ppl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@babela4985</td>\n",
       "      <td>😂😂</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@subsbribeorikillyou</td>\n",
       "      <td>this guy is Sean Stricklands lil brother prolly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>@devanjohnson737</td>\n",
       "      <td>The first one is such a good bit 😂</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>@arthursandomine5464</td>\n",
       "      <td>By the time the cripple &amp;quot;fuucked up his w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>@delanowatts2796</td>\n",
       "      <td>Nah get this man to 1 mil please😂😂</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>@Priest_Of_Zebak</td>\n",
       "      <td>&lt;a href=\"https://www.youtube.com/watch?v=E4UJg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>@hope6571</td>\n",
       "      <td>I love David, bought and read his books and I ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 author                                            comment\n",
       "0               @Kbk07_                      i want David to react to this\n",
       "1          @TheDeepKing                              This is diabolical 😂😂\n",
       "2            @Ivixation             i bet this actually triggered some ppl\n",
       "3           @babela4985                                                 😂😂\n",
       "4  @subsbribeorikillyou    this guy is Sean Stricklands lil brother prolly\n",
       "5      @devanjohnson737                 The first one is such a good bit 😂\n",
       "6  @arthursandomine5464  By the time the cripple &quot;fuucked up his w...\n",
       "7      @delanowatts2796                 Nah get this man to 1 mil please😂😂\n",
       "8      @Priest_Of_Zebak  <a href=\"https://www.youtube.com/watch?v=E4UJg...\n",
       "9             @hope6571  I love David, bought and read his books and I ..."
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_url = \"https://www.youtube.com/watch?v=E4UJgakxzC4\"\n",
    "df = fetch_youtube_comments(video_url)\n",
    "print(df.shape)\n",
    "df.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
